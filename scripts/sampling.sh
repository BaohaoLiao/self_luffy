#!/bin/bash

cd /data/chatgpt-training-slc-a100/data/baliao/hint/00_data_process/hint

DATA="/mnt/nushare2/data/baliao/hint/data/openr1/validated.json"
MODEL="/mnt/nushare2/data/baliao/PLLMs/meta-llama/Llama-3.2-3B-Instruct"
MODEL_NAME="Llama-3.2-3B-Instruct"
N=8
SAVE_DIR="/mnt/nushare2/data/baliao/hint/data/openr1/sampling/${MODEL_NAME}_n${N}"
GPUS=(0 1 2 3 4 5 6 7)

# Generate data in parallel
echo "Starting parallel data generation..."
for ((i=0; i<${#GPUS[@]}; i++)); do
    CUDA_VISIBLE_DEVICES=${i} python -m data_process.sampling \
        dataset_path=${DATA} \
        world_size=${#GPUS[@]} \
        local_idx=${i} \
        model_name_or_path=${MODEL} \
        n=${N} \
        output_dir=${SAVE_DIR} &
done

# Wait for all jobs to complete
wait

# Build the file list dynamically
echo "Merging output files..."
FILE_LIST=""
for ((i=0; i<${#GPUS[@]}; i++)); do
    FILE_LIST="${FILE_LIST} ${SAVE_DIR}/${i}.json"
done

cat ${FILE_LIST} > ${SAVE_DIR}/merged.json

# Compute score
echo "Computing scores..."
python -m data_process.compute_score \
    dataset_path=${SAVE_DIR}/merged.json \

chown -R 110541254:110541254 ${SAVE_DIR}